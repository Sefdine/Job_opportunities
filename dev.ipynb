{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('job_opportunities.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Requirment of the company ': 'Requirment of the company'}, inplace=True)\n",
    "\n",
    "# Drop last row\n",
    "df.drop(df.loc[df['Company'].isnull()].index, axis='rows', inplace=True)\n",
    "\n",
    "# Drop duplicated rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save null salary in another dataframe\n",
    "df_salary_isnull = df.loc[df['Salary'].isnull()]\n",
    "\n",
    "# Delete those null salary from the main dataframe\n",
    "df.drop(df_salary_isnull.index, inplace=True)\n",
    "\n",
    "# Create new column that contains stars True or False\n",
    "df['Salary_has_star'] = df['Salary'].str.contains('\\*')\n",
    "\n",
    "# Take +, *, and K from salary \n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.replace(x, '+', ''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.replace(x, '*', ''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.replace(x, 'K', ''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.strip(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is_number\n",
    "def is_number(number):\n",
    "    try:\n",
    "        number = float(number)\n",
    "        return isinstance(number, float)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "# Function take_currency\n",
    "import re\n",
    "def take_currency(salary):\n",
    "    salary = re.sub(r'[0-9+]', '', salary)\n",
    "    return str.strip(salary)\n",
    "\n",
    "# Function remove_currency\n",
    "def remove_currency(salary):\n",
    "    salary = re.sub(r'[^0-9]', '', salary)\n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column that contain the currency\n",
    "df['Currency'] = df['Salary'].apply(lambda x: 'USD' if is_number(x) else take_currency(x))\n",
    "\n",
    "# Remove currency from salary\n",
    "df['Salary'] = df['Salary'].apply(lambda x: remove_currency(x))\n",
    "\n",
    "# Change salary type to float and multiply to 1000\n",
    "df['Salary'] = df['Salary'].astype(float) * 1000\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6249/69151303.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Salary'][i] = converter.convert(df['Salary'][i], currency, \"USD\")\n"
     ]
    }
   ],
   "source": [
    "# Normalize salary\n",
    "from currency_converter import CurrencyConverter\n",
    "\n",
    "converter = CurrencyConverter()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    currency = df['Currency'][i]\n",
    "\n",
    "    if currency != 'USD':\n",
    "        df['Salary'][i] = converter.convert(df['Salary'][i], currency, \"USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the currency column after transforming the salary\n",
    "df.drop('Currency', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = df['Location'].apply(lambda x: str.lower(str.strip(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import Geotext\n",
    "# from geotext import GeoText\n",
    "\n",
    "# # Create country column\n",
    "# df['Country'] = df['Location'].apply(lambda x: GeoText(x).countries[0] if len(GeoText(x).countries) > 0 else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirement and facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change those to list\n",
    "df['Requirment of the company'] = df['Requirment of the company'].apply(lambda x: str.split(x, ','))\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: str.split(x, ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to delete all empty strings\n",
    "def delete_empty_in_list(listname):\n",
    "    while '' in listname:\n",
    "        listname.remove('')\n",
    "    return listname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty strings on the lists\n",
    "df['Requirment of the company'] = df['Requirment of the company'].apply(lambda x: delete_empty_in_list(x))\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: delete_empty_in_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle empty facilities\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: ['No facilities'] if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle experience level null values\n",
    "df['Experience level'] = df['Experience level'].apply(lambda x: 'Not specified' if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keywords for jobs\n",
    "data_science_keywords = [\n",
    "    'scientist', 'science', 'data analysis', 'data analyst', 'data mining', 'predictive modeling',\n",
    "    'machine learning', 'statistical analysis', 'data visualization',\n",
    "    'exploratory data analysis', 'data cleaning', 'feature engineering',\n",
    "    'regression analysis', 'classification', 'clustering',\n",
    "    'natural language processing', 'time series analysis', 'data product manager', 'research analyst', 'data analytics',\n",
    "    'data quality', 'bi', 'business intelligence', 'data management', 'data project management', 'digital analytics',\n",
    "    'data modeler', 'data product owner', 'cloud database analyst', 'data manager', 'data strategy', 'data specialist',\n",
    "    'analytics engineer', 'master data', 'data operations', 'data operator', 'dataops', 'data strategist', 'data systems',\n",
    "    'data reporter', 'data and control systems', 'data developer', 'data analyse', 'data visualisation', 'analyst',\n",
    "    'data strategies', 'head of data', 'ml'\n",
    "]\n",
    "\n",
    "big_data_keywords = [\n",
    "    'big', 'big data', 'data engineer', 'data enginner','hadoop', 'apache spark', 'spark', 'nosql', 'mapreduce',\n",
    "    'distributed computing', 'data storage and retrieval', 'data scalability', 'etl',\n",
    "    'data volume', 'data velocity', 'data variety', 'data processing',\n",
    "    'data architecture', 'data streaming', 'data lakes', 'streaming data pipelines', 'data architect', 'data storage',\n",
    "    'data pipeline', 'data platform', 'dataset', 'databricks', 'data integrations', 'data infrastructure', 'data integration',\n",
    "    'database engineer', 'data lake', 'data modeller', 'data production', 'cloud data', 'data modelling', 'data modeling',\n",
    "    'database tools'\n",
    "]\n",
    "\n",
    "ai_keywords = [\n",
    "    'artificial intelligence', 'ai', 'machine learning', 'deep learning',\n",
    "    'neural networks', 'natural language processing', 'computer vision',\n",
    "    'reinforcement learning', 'robotics', 'expert systems',\n",
    "    'cognitive computing', 'ai algorithms', 'sentiment analysis',\n",
    "    'speech recognition', 'image recognition', 'autonomous systems', 'ml',\n",
    "    'autonomous', 'autonomy', 'robotic', 'vision', 'text analytics', 'chatbot', 'nlp', 'model inference'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify job titles into DS, AI or Big Data\n",
    "def classify_job(title):\n",
    "    str.lower(title)\n",
    "    categories = []\n",
    "    if any(keyword in title for keyword in ai_keywords):\n",
    "        categories.append('Artificial Intelligence')\n",
    "    if any(keyword in title for keyword in data_science_keywords):\n",
    "        categories.append('Data Science')\n",
    "    if any(keyword in title for keyword in big_data_keywords):\n",
    "        categories.append('Big Data')\n",
    "    if not categories :\n",
    "        categories.append('Other')\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Category'] = df['Job Title'].apply(lambda x: classify_job(x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stockage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tendance clés en IA, DS, Big DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from sqlalchemy import create_engine, text, Integer, String, Float, Boolean, Date, Column, inspect, UniqueConstraint, ForeignKey\n",
    "from sqlalchemy.orm import create_session, declarative_base, Relationship, sessionmaker\n",
    "\n",
    "username = 'SA'\n",
    "password = 'YourPassword123'\n",
    "hostname = 'localhost'\n",
    "database = 'Job_opportunities'\n",
    "driver = 'ODBC+Driver+18+for+SQL+Server'\n",
    "\n",
    "connection_string = f'mssql+pyodbc://{username}:{password}@{hostname}/{database}?driver={driver}&Encrypt=No'\n",
    "\n",
    "# Create sqlalchemy engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create tables\n",
    "\n",
    "# Create a base\n",
    "Base = declarative_base()\n",
    "\n",
    "# locations\n",
    "class Locations(Base):\n",
    "    __tablename__ = 'locations'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    location = Column(String(255), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(location, name='locations_location_UQ'),)\n",
    "\n",
    "# facilities\n",
    "class Facilities(Base):\n",
    "    __tablename__ = 'facilities'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    facility = Column(String(255), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(facility, name='facilities_facility_UQ'),)\n",
    "\n",
    "# job_types\n",
    "class JobTypes(Base):\n",
    "    __tablename__ = 'job_types'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    type = Column(String(50), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(type, name='job_types_type_UQ'),)\n",
    "\n",
    "# experience_levels\n",
    "class ExperienceLevels(Base):\n",
    "    __tablename__ = 'experience_levels'\n",
    "    \n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    level = Column(String(50), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(level, name='experience_levels_level_UQ'),)\n",
    "\n",
    "# requirements\n",
    "class Requirements(Base):\n",
    "    __tablename__ = 'requirements'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    requirement = Column(String(255), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(requirement, name='requirements_requirement_UQ'),)\n",
    "\n",
    "# jobs\n",
    "class Jobs(Base):\n",
    "    __tablename__ = 'jobs'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    title = Column(String, nullable=False)\n",
    "    salary = Column(Float, nullable=False)\n",
    "    salary_has_star = Column(Boolean, nullable=False)\n",
    "    job_type_id = Column(Integer, ForeignKey('job_types.id'))\n",
    "    location_id = Column(Integer, ForeignKey('locations.id'))\n",
    "    experience_level_id = Column(Integer, ForeignKey('experience_levels.id'))\n",
    "\n",
    "    # Relationships\n",
    "    job_types_jobs = Relationship('JobTypes', backref='jobs')\n",
    "    locations_jobs = Relationship('Locations', backref='jobs')\n",
    "    experience_levels_jobs = Relationship('ExperienceLevels', backref='jobs')\n",
    "\n",
    "# job_facilities\n",
    "class JobFacilities(Base):\n",
    "    __tablename__ = 'job_facilities'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    job_id = Column(Integer, ForeignKey('jobs.id'))\n",
    "    facility_id = Column(Integer, ForeignKey('facilities.id'))\n",
    "\n",
    "    # Relationships\n",
    "    job_jf = Relationship('Jobs', backref='job_facilities')\n",
    "    facility_fj = Relationship('Facilities', backref='job_facilities')\n",
    "\n",
    "# job_requirements\n",
    "class JobRequirements(Base):\n",
    "    __tablename__ = 'job_requirements'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    requirement_id = Column(Integer, ForeignKey('requirements.id'))\n",
    "    job_id = Column(Integer, ForeignKey('jobs.id'))\n",
    "\n",
    "    # Relationships\n",
    "    requirement_jr = Relationship('Requirements', backref='job_requirements')\n",
    "    job_jr = Relationship('Jobs', backref='job_requirements')\n",
    "\n",
    "\n",
    "# Categories\n",
    "class Categories(Base):\n",
    "    __tablename__ = 'categories'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    category = Column(String(255), nullable=False)\n",
    "\n",
    "    # UniqueConstraints\n",
    "    __table_args__ = (UniqueConstraint(category, name='categories_category_UQ'),)\n",
    "\n",
    "# Job_categories\n",
    "class JobCategories(Base):\n",
    "    __tablename__ = 'job_categories'\n",
    "\n",
    "    # Column\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    category_id = Column(Integer, ForeignKey('categories.id'))\n",
    "    job_id = Column(Integer, ForeignKey('jobs.id'))\n",
    "\n",
    "    # Relationships\n",
    "    category_jc = Relationship('Categories', backref='job_categories')\n",
    "    job_jc = Relationship('Jobs', backref='job_categories')\n",
    "\n",
    "try:\n",
    "    Base.metadata.create_all(engine)\n",
    "    print('Tables created successfully')\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categories',\n",
       " 'experience_levels',\n",
       " 'facilities',\n",
       " 'job_categories',\n",
       " 'job_facilities',\n",
       " 'job_requirements',\n",
       " 'job_types',\n",
       " 'jobs',\n",
       " 'locations',\n",
       " 'requirements']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with engine.connect() as conn:\n",
    "#     conn.execute(text('drop table categories'))\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion des données dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session\n",
    "session = create_session(engine)\n",
    "\n",
    "# Tables that don't have foregin keys\n",
    "try:\n",
    "    # Locations\n",
    "    for location in df['Location'].unique():\n",
    "        new_location = Locations(location=str(location))\n",
    "        session.add(new_location)\n",
    "\n",
    "    # Facilities\n",
    "    for facility in df['Facilities'].explode().unique():\n",
    "        new_facility = Facilities(facility=str(facility))\n",
    "        session.add(new_facility)\n",
    "\n",
    "    # Categories\n",
    "    for category in df['Job Category'].explode().unique():\n",
    "        new_category = Categories(category=str(category))\n",
    "        session.add(new_category)\n",
    "\n",
    "    # Requirements\n",
    "    for requirement in df['Requirment of the company'].explode().unique():\n",
    "        new_requirement = Requirements(requirement=str(requirement))\n",
    "        session.add(new_requirement)\n",
    "\n",
    "    # Experience levels\n",
    "    for experience_level in df['Experience level'].unique():\n",
    "        new_experience_level = ExperienceLevels(level=str(experience_level))\n",
    "        session.add(new_experience_level)\n",
    "\n",
    "    # Job types\n",
    "    for job_type in df['Job Type'].unique():\n",
    "        new_job_type = JobTypes(type=str(job_type))\n",
    "        session.add(new_job_type)\n",
    "\n",
    "    session.commit()\n",
    "    print('All rows inserted successfully')\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    print('Error', e)\n",
    "    print('No row inserted')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session\n",
    "session = create_session(engine)\n",
    "\n",
    "# insert into jobs\n",
    "with session.begin():\n",
    "    try:\n",
    "        for i in range(len(df)):\n",
    "            title = df['Job Title'][i]\n",
    "            salary = float(df['Salary'][i])\n",
    "            salary_has_star = bool(df['Salary_has_star'][i])\n",
    "            job_type = df['Job Type'][i]\n",
    "            job_type_id = session.query(JobTypes).filter(JobTypes.type==job_type).first().id\n",
    "            location = df['Location'][i]\n",
    "            location_id = session.query(Locations).filter_by(location=location).first().id\n",
    "            experience_level = df['Experience level'][i]\n",
    "            experience_level_id = session.query(ExperienceLevels).filter_by(level=experience_level).first().id\n",
    "\n",
    "            # new jobs\n",
    "            new_job = Jobs(\n",
    "                title=title,\n",
    "                salary=salary,\n",
    "                salary_has_star=salary_has_star,\n",
    "                job_type_id=job_type_id,\n",
    "                location_id=location_id,\n",
    "                experience_level_id=experience_level_id\n",
    "            )\n",
    "            session.add(new_job)\n",
    "\n",
    "        # Commit the transaction\n",
    "        session.commit()\n",
    "        print('All rows inserted successfully')\n",
    "    except Exception as e:\n",
    "        # Roll back the transaction\n",
    "        session.rollback()\n",
    "        print('Error ',e)\n",
    "        print('No row inserted')\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60309, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe to insert in the database\n",
    "df_to_db = df[[\n",
    "    'Job Title', \n",
    "    'Facilities', \n",
    "    'Job Category',\n",
    "    'Requirment of the company'\n",
    "]].explode('Facilities', ignore_index=True)\n",
    "df_to_db = df_to_db.explode('Job Category', ignore_index=True)\n",
    "df_to_db = df_to_db.explode('Requirment of the company', ignore_index=True)\n",
    "df_to_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into relations tables\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "\n",
    "for i in range(len(df_to_db)):\n",
    "    with session.begin():    \n",
    "        try:\n",
    "            # Get job_id\n",
    "            title = df_to_db['Job Title'][i]\n",
    "            job_id = session.query(Jobs).filter_by(title=title).first().id\n",
    "\n",
    "            # Get facility id \n",
    "            facility = df_to_db['Facilities'][i]\n",
    "            facility_id = session.query(Facilities).filter_by(facility=facility).first().id\n",
    "\n",
    "            # Get category id\n",
    "            category = df_to_db['Job Category'][i]\n",
    "            category_id = session.query(Categories).filter_by(category=category).first().id\n",
    "\n",
    "            # Get the requirement id\n",
    "            requirement = df_to_db['Requirment of the company'][i]\n",
    "            requirement_id = session.query(Requirements).filter_by(requirement=requirement).first().id\n",
    "\n",
    "            # Insert row in job facility\n",
    "            new_job_facility = JobFacilities(job_id=job_id, facility_id=facility_id)\n",
    "            session.add(new_job_facility)\n",
    "\n",
    "            # Insert row in job categories\n",
    "            new_job_category = JobCategories(category_id=category_id, job_id=job_id)\n",
    "            session.add(new_job_category)\n",
    "\n",
    "            # Insert row in job requirements\n",
    "            new_job_requirement = JobRequirements(requirement_id=requirement_id, job_id=job_id)\n",
    "            session.add(new_job_requirement)\n",
    "            \n",
    "            # Commit the transaction\n",
    "            session.commit()\n",
    "            print(f\"Row {i} inserted successfully\", end='\\r')\n",
    "        except Exception as e:\n",
    "            # Roll back the transaction\n",
    "            session.rollback()\n",
    "            print(f\"Row {i} has a problem\")\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60309"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.query(JobRequirements).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse et visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import plotly package\n",
    "import plotly.express as px\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
