{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('job_opportunities.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Requirment of the company ': 'Requirment of the company'}, inplace=True)\n",
    "\n",
    "# Drop last row\n",
    "df.drop(df.loc[df['Company'].isnull()].index, axis='rows', inplace=True)\n",
    "\n",
    "# Drop duplicated rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Title'] = df['Job Title'].apply(lambda x: str.lower(str.strip(x)))\n",
    "df['Location'] = df['Location'].apply(lambda x: str.lower(str.strip(x)))\n",
    "\n",
    "# Drop duplicated rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save null salary in another dataframe\n",
    "df_salary_isnull = df.loc[df['Salary'].isnull()]\n",
    "\n",
    "# Delete those null salary from the main dataframe\n",
    "df.drop(df_salary_isnull.index, inplace=True)\n",
    "\n",
    "# Create new column that contains stars True or False\n",
    "df['Salary_has_star'] = df['Salary'].str.contains('\\*')\n",
    "\n",
    "# Take +, *, and K from salary \n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.replace(x, '+', ''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.replace(x, '*', ''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.replace(x, 'K', ''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: str.strip(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is_number\n",
    "def is_number(number):\n",
    "    try:\n",
    "        number = float(number)\n",
    "        return isinstance(number, float)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "# Function take_currency\n",
    "import re\n",
    "def take_currency(salary):\n",
    "    salary = re.sub(r'[0-9+]', '', salary)\n",
    "    return str.strip(salary)\n",
    "\n",
    "# Function remove_currency\n",
    "def remove_currency(salary):\n",
    "    salary = re.sub(r'[^0-9]', '', salary)\n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column that contain the currency\n",
    "df['Currency'] = df['Salary'].apply(lambda x: 'USD' if is_number(x) else take_currency(x))\n",
    "\n",
    "# Remove currency from salary\n",
    "df['Salary'] = df['Salary'].apply(lambda x: remove_currency(x))\n",
    "\n",
    "# Change salary type to float and multiply to 1000\n",
    "df['Salary'] = df['Salary'].astype(float) * 1000\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6138/69151303.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Salary'][i] = converter.convert(df['Salary'][i], currency, \"USD\")\n"
     ]
    }
   ],
   "source": [
    "# Normalize salary\n",
    "from currency_converter import CurrencyConverter\n",
    "\n",
    "converter = CurrencyConverter()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    currency = df['Currency'][i]\n",
    "\n",
    "    if currency != 'USD':\n",
    "        df['Salary'][i] = converter.convert(df['Salary'][i], currency, \"USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the currency column after transforming the salary\n",
    "df.drop('Currency', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = df['Location'].apply(lambda x: str.lower(str.strip(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import Geotext\n",
    "# from geotext import GeoText\n",
    "\n",
    "# # Create country column\n",
    "# df['Country'] = df['Location'].apply(lambda x: GeoText(x).countries[0] if len(GeoText(x).countries) > 0 else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirement and facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change those to list\n",
    "df['Requirment of the company'] = df['Requirment of the company'].apply(lambda x: str.split(x, ','))\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: str.split(x, ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to delete all empty strings\n",
    "def delete_empty_in_list(listname):\n",
    "    while '' in listname:\n",
    "        listname.remove('')\n",
    "    return listname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty strings on the lists\n",
    "df['Requirment of the company'] = df['Requirment of the company'].apply(lambda x: delete_empty_in_list(x))\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: delete_empty_in_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle empty facilities\n",
    "df['Facilities'] = df['Facilities'].apply(lambda x: ['No facilities'] if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle experience level null values\n",
    "df['Experience level'] = df['Experience level'].apply(lambda x: 'Not specified' if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keywords for jobs\n",
    "data_science_keywords = [\n",
    "    'scientist', 'science', 'data analysis', 'data analyst', 'data mining', 'predictive modeling',\n",
    "    'machine learning', 'statistical analysis', 'data visualization',\n",
    "    'exploratory data analysis', 'data cleaning', 'feature engineering',\n",
    "    'regression analysis', 'classification', 'clustering',\n",
    "    'natural language processing', 'time series analysis', 'data product manager', 'research analyst', 'data analytics',\n",
    "    'data quality', 'bi', 'business intelligence', 'data management', 'data project management', 'digital analytics',\n",
    "    'data modeler', 'data product owner', 'cloud database analyst', 'data manager', 'data strategy', 'data specialist',\n",
    "    'analytics engineer', 'master data', 'data operations', 'data operator', 'dataops', 'data strategist', 'data systems',\n",
    "    'data reporter', 'data and control systems', 'data developer', 'data analyse', 'data visualisation', 'analyst',\n",
    "    'data strategies', 'head of data', 'ml'\n",
    "]\n",
    "\n",
    "big_data_keywords = [\n",
    "    'big', 'big data', 'data engineer', 'data enginner','hadoop', 'apache spark', 'spark', 'nosql', 'mapreduce',\n",
    "    'distributed computing', 'data storage and retrieval', 'data scalability', 'etl',\n",
    "    'data volume', 'data velocity', 'data variety', 'data processing',\n",
    "    'data architecture', 'data streaming', 'data lakes', 'streaming data pipelines', 'data architect', 'data storage',\n",
    "    'data pipeline', 'data platform', 'dataset', 'databricks', 'data integrations', 'data infrastructure', 'data integration',\n",
    "    'database engineer', 'data lake', 'data modeller', 'data production', 'cloud data', 'data modelling', 'data modeling',\n",
    "    'database tools'\n",
    "]\n",
    "\n",
    "ai_keywords = [\n",
    "    'artificial intelligence', 'ai', 'machine learning', 'deep learning',\n",
    "    'neural networks', 'natural language processing', 'computer vision',\n",
    "    'reinforcement learning', 'robotics', 'expert systems',\n",
    "    'cognitive computing', 'ai algorithms', 'sentiment analysis',\n",
    "    'speech recognition', 'image recognition', 'autonomous systems', 'ml',\n",
    "    'autonomous', 'autonomy', 'robotic', 'vision', 'text analytics', 'chatbot', 'nlp', 'model inference'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify job titles into DS, AI or Big Data\n",
    "def classify_job(title):\n",
    "    str.lower(title)\n",
    "    categories = []\n",
    "    if any(keyword in title for keyword in ai_keywords):\n",
    "        categories.append('Artificial Intelligence')\n",
    "    if any(keyword in title for keyword in data_science_keywords):\n",
    "        categories.append('Data Science')\n",
    "    if any(keyword in title for keyword in big_data_keywords):\n",
    "        categories.append('Big Data')\n",
    "    if not categories :\n",
    "        categories.append('Other')\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Job Category column\n",
    "df['Job Category'] = df['Job Title'].apply(lambda x: classify_job(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Salary_has_star</th>\n",
       "      <th>Job Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>clinical data analyst</td>\n",
       "      <td>richardson, tx, united states</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>[Computer Science, Data quality, Genetics, Mat...</td>\n",
       "      <td>[No facilities]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Data Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>aml/cft &amp; data analyst</td>\n",
       "      <td>ebène, mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>[Agile, Data management, Finance, Security]</td>\n",
       "      <td>[No facilities]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Artificial Intelligence, Data Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>south jordan, ut, united states</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Not specified</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>[Agile, Architecture, AWS, Computer Science, C...</td>\n",
       "      <td>[Career development]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Artificial Intelligence, Data Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>application developer &amp; data analyst</td>\n",
       "      <td>nonantola, italy</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>[Engineering, Industrial, Oracle, Power BI, R,...</td>\n",
       "      <td>[No facilities]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Data Science]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>data engineer full time (public sector) usa</td>\n",
       "      <td>arlington, va, united states</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>[AWS, Azure, Computer Science, Consulting, Dat...</td>\n",
       "      <td>[Flex hours, Flex vacation, Parental leave, Un...</td>\n",
       "      <td>False</td>\n",
       "      <td>[Big Data]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company                                    Job Title  \\\n",
       "0              SGS                        clinical data analyst   \n",
       "1          Ocorian                       aml/cft & data analyst   \n",
       "2           Cricut                    machine learning engineer   \n",
       "3      Bosch Group         application developer & data analyst   \n",
       "4  Publicis Groupe  data engineer full time (public sector) usa   \n",
       "\n",
       "                          Location   Job Type Experience level    Salary  \\\n",
       "0    richardson, tx, united states  Full Time      Entry-level   48000.0   \n",
       "1                 ebène, mauritius  Full Time      Entry-level   48000.0   \n",
       "2  south jordan, ut, united states  Full Time    Not specified   90000.0   \n",
       "3                 nonantola, italy  Full Time      Entry-level   48000.0   \n",
       "4     arlington, va, united states  Full Time        Mid-level  108000.0   \n",
       "\n",
       "                           Requirment of the company  \\\n",
       "0  [Computer Science, Data quality, Genetics, Mat...   \n",
       "1        [Agile, Data management, Finance, Security]   \n",
       "2  [Agile, Architecture, AWS, Computer Science, C...   \n",
       "3  [Engineering, Industrial, Oracle, Power BI, R,...   \n",
       "4  [AWS, Azure, Computer Science, Consulting, Dat...   \n",
       "\n",
       "                                          Facilities  Salary_has_star  \\\n",
       "0                                    [No facilities]             True   \n",
       "1                                    [No facilities]             True   \n",
       "2                               [Career development]             True   \n",
       "3                                    [No facilities]             True   \n",
       "4  [Flex hours, Flex vacation, Parental leave, Un...            False   \n",
       "\n",
       "                              Job Category  \n",
       "0                           [Data Science]  \n",
       "1  [Artificial Intelligence, Data Science]  \n",
       "2  [Artificial Intelligence, Data Science]  \n",
       "3                           [Data Science]  \n",
       "4                               [Big Data]  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stockage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from sqlalchemy import create_engine, text, Integer, String, Float, Boolean, Date, Column, inspect, UniqueConstraint, ForeignKey, func, desc, select, Index\n",
    "from sqlalchemy.orm import create_session, declarative_base, Relationship, sessionmaker\n",
    "\n",
    "username = 'SA'\n",
    "password = 'YourPassword123'\n",
    "hostname = '172.17.0.1'\n",
    "database = 'job_opportunities'\n",
    "driver = 'ODBC+Driver+18+for+SQL+Server'\n",
    "\n",
    "connection_string = f'mssql+pyodbc://{username}:{password}@{hostname}/{database}?driver={driver}&Encrypt=No'\n",
    "\n",
    "# Create sqlalchemy engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create tables\n",
    "\n",
    "# Create a base\n",
    "Base = declarative_base()\n",
    "\n",
    "# locations\n",
    "class Locations(Base):\n",
    "    __tablename__ = 'locations'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    location = Column(String(255), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(location, name='locations_location_UQ'),)\n",
    "\n",
    "# facilities\n",
    "class Facilities(Base):\n",
    "    __tablename__ = 'facilities'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    facility = Column(String(255), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(facility, name='facilities_facility_UQ'),)\n",
    "\n",
    "    # Indexes\n",
    "    facility_index = Index('facilities_facility', facility)\n",
    "\n",
    "# job_types\n",
    "class JobTypes(Base):\n",
    "    __tablename__ = 'job_types'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    type = Column(String(50), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(type, name='job_types_type_UQ'),)\n",
    "\n",
    "# experience_levels\n",
    "class ExperienceLevels(Base):\n",
    "    __tablename__ = 'experience_levels'\n",
    "    \n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    level = Column(String(50), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(level, name='experience_levels_level_UQ'),)\n",
    "\n",
    "# requirements\n",
    "class Requirements(Base):\n",
    "    __tablename__ = 'requirements'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    requirement = Column(String(255), nullable=False)\n",
    "\n",
    "    # Constraints\n",
    "    __table_args__ = (UniqueConstraint(requirement, name='requirements_requirement_UQ'),)\n",
    "\n",
    "    # Indexes\n",
    "    requirement_index = Index('requirements_requirement_index', requirement)\n",
    "\n",
    "# companies\n",
    "class Companies(Base):\n",
    "    __tablename__ = 'companies'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    company = Column(String(255), nullable=False)\n",
    "\n",
    "    # constraints\n",
    "    __table_args__ = (UniqueConstraint(company, name='companies_company_UQ'),)\n",
    "\n",
    "    # Indexes\n",
    "    company_index = Index('companies_company_index', company)\n",
    "\n",
    "# jobs\n",
    "class Jobs(Base):\n",
    "    __tablename__ = 'jobs'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    title = Column(String(255), nullable=False)\n",
    "    salary = Column(Float, nullable=False)\n",
    "    salary_has_star = Column(Boolean, nullable=False)\n",
    "    job_type_id = Column(Integer, ForeignKey('job_types.id'))\n",
    "    location_id = Column(Integer, ForeignKey('locations.id'))\n",
    "    experience_level_id = Column(Integer, ForeignKey('experience_levels.id'))\n",
    "    company_id = Column(Integer, ForeignKey('companies.id'))\n",
    "\n",
    "    # UniqueConstraint\n",
    "    __table_args__ = (UniqueConstraint(\n",
    "        title, \n",
    "        salary, \n",
    "        salary_has_star, \n",
    "        job_type_id,\n",
    "        location_id,\n",
    "        experience_level_id,\n",
    "        company_id,\n",
    "        name='jobs_UQ'\n",
    "    ),)\n",
    "\n",
    "    # Relationships\n",
    "    job_types_jobs = Relationship('JobTypes', backref='jobs')\n",
    "    locations_jobs = Relationship('Locations', backref='jobs')\n",
    "    experience_levels_jobs = Relationship('ExperienceLevels', backref='jobs')\n",
    "    companies_jobs = Relationship('Companies', backref='jobs')\n",
    "\n",
    "    # Indexes\n",
    "    title_index = Index('jobs_title_index', title)\n",
    "    salary_index = Index('jobs_salary_index', salary)\n",
    "\n",
    "# job_facilities\n",
    "class JobFacilities(Base):\n",
    "    __tablename__ = 'job_facilities'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    job_id = Column(Integer, ForeignKey('jobs.id'))\n",
    "    facility_id = Column(Integer, ForeignKey('facilities.id'))\n",
    "\n",
    "    # Unique constraints\n",
    "    __table_args__ = (UniqueConstraint(job_id, facility_id, name='job_facility_UQ'),)\n",
    "\n",
    "    # Relationships\n",
    "    job_jf = Relationship('Jobs', backref='job_facilities')\n",
    "    facility_fj = Relationship('Facilities', backref='job_facilities')\n",
    "\n",
    "# job_requirements\n",
    "class JobRequirements(Base):\n",
    "    __tablename__ = 'job_requirements'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    requirement_id = Column(Integer, ForeignKey('requirements.id'))\n",
    "    job_id = Column(Integer, ForeignKey('jobs.id'))\n",
    "\n",
    "    # Unique constraints\n",
    "    __table_args__ = (UniqueConstraint(requirement_id, job_id, name='job_requirements_UQ'),)\n",
    "\n",
    "    # Relationships\n",
    "    requirement_jr = Relationship('Requirements', backref='job_requirements')\n",
    "    job_jr = Relationship('Jobs', backref='job_requirements')\n",
    "\n",
    "\n",
    "# Categories\n",
    "class Categories(Base):\n",
    "    __tablename__ = 'categories'\n",
    "\n",
    "    # Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    category = Column(String(255), nullable=False)\n",
    "\n",
    "    # UniqueConstraints\n",
    "    __table_args__ = (UniqueConstraint(category, name='categories_category_UQ'),)\n",
    "\n",
    "    # Indexes\n",
    "    category_index = Index('categories_category_index', category)\n",
    "\n",
    "# Job_categories\n",
    "class JobCategories(Base):\n",
    "    __tablename__ = 'job_categories'\n",
    "\n",
    "    # Column\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    category_id = Column(Integer, ForeignKey('categories.id'))\n",
    "    job_id = Column(Integer, ForeignKey('jobs.id'))\n",
    "\n",
    "    # Unique constraints\n",
    "    __table_args__ = (UniqueConstraint(category_id, job_id, name='job_categories_UQ'),)\n",
    "\n",
    "    # Relationships\n",
    "    category_jc = Relationship('Categories', backref='job_categories')\n",
    "    job_jc = Relationship('Jobs', backref='job_categories')\n",
    "\n",
    "try:\n",
    "    Base.metadata.create_all(engine)\n",
    "    print('Tables created successfully')\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categories',\n",
       " 'companies',\n",
       " 'experience_levels',\n",
       " 'facilities',\n",
       " 'job_categories',\n",
       " 'job_facilities',\n",
       " 'job_requirements',\n",
       " 'job_types',\n",
       " 'jobs',\n",
       " 'locations',\n",
       " 'requirements']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session\n",
    "session = create_session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with engine.connect() as conn:\n",
    "    # conn.execute(text('drop table job_requirements'))\n",
    "    # conn.execute(text('drop table job_facilities'))\n",
    "    # conn.execute(text('drop table job_categories'))\n",
    "    # conn.execute(text('drop table jobs'))\n",
    "    # conn.execute(text('drop table job_types'))\n",
    "    # conn.execute(text('drop table locations'))\n",
    "    # conn.execute(text('drop table categories'))\n",
    "    # conn.execute(text('drop table experience_levels'))\n",
    "    # conn.execute(text('drop table facilities'))\n",
    "    # conn.execute(text('drop table requirements'))\n",
    "    # conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion des données dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows inserted successfully\n"
     ]
    }
   ],
   "source": [
    "# Tables that don't have foregin keys\n",
    "try:\n",
    "    # Locations\n",
    "    for location in df['Location'].unique():\n",
    "        new_location = Locations(location=str(location))\n",
    "        session.add(new_location)\n",
    "\n",
    "    # Facilities\n",
    "    for facility in df['Facilities'].explode().unique():\n",
    "        new_facility = Facilities(facility=str(facility))\n",
    "        session.add(new_facility)\n",
    "\n",
    "    # Categories\n",
    "    for category in df['Job Category'].explode().unique():\n",
    "        new_category = Categories(category=str(category))\n",
    "        session.add(new_category)\n",
    "\n",
    "    # Requirements\n",
    "    for requirement in df['Requirment of the company'].explode().unique():\n",
    "        new_requirement = Requirements(requirement=str(requirement))\n",
    "        session.add(new_requirement)\n",
    "\n",
    "    # Experience levels\n",
    "    for experience_level in df['Experience level'].unique():\n",
    "        new_experience_level = ExperienceLevels(level=str(experience_level))\n",
    "        session.add(new_experience_level)\n",
    "\n",
    "    # Job types\n",
    "    for job_type in df['Job Type'].unique():\n",
    "        new_job_type = JobTypes(type=str(job_type))\n",
    "        session.add(new_job_type)\n",
    "\n",
    "    session.commit()\n",
    "    print('All rows inserted successfully')\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    print('Error', e)\n",
    "    print('No row inserted')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the insertion went good\n",
    "df['Facilities'].explode().unique().shape[0] == session.query(Facilities).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12/2361147866.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  jobs_df.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "job_columns = [\n",
    "    'Job Title', \n",
    "    'Salary', \n",
    "    'Salary_has_star', \n",
    "    'Job Type', \n",
    "    'Location',\n",
    "    'Experience level'\n",
    "]\n",
    "jobs_df = df[job_columns]\n",
    "jobs_df.drop_duplicates(inplace=True)\n",
    "jobs_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows inserted successfully\n"
     ]
    }
   ],
   "source": [
    "# Create session\n",
    "session = create_session(engine)\n",
    "\n",
    "# insert into jobs\n",
    "with session.begin():\n",
    "    try:\n",
    "        for i in range(len(jobs_df)):\n",
    "            title = jobs_df['Job Title'][i]\n",
    "            salary = float(jobs_df['Salary'][i])\n",
    "            salary_has_star = bool(jobs_df['Salary_has_star'][i])\n",
    "            job_type = jobs_df['Job Type'][i]\n",
    "            job_type_id = session.query(JobTypes).filter(JobTypes.type==job_type).first().id\n",
    "            location = jobs_df['Location'][i]\n",
    "            location_id = session.query(Locations).filter_by(location=location).first().id\n",
    "            experience_level = jobs_df['Experience level'][i]\n",
    "            experience_level_id = session.query(ExperienceLevels).filter_by(level=experience_level).first().id\n",
    "\n",
    "            # new jobs\n",
    "            new_job = Jobs(\n",
    "                title=title,\n",
    "                salary=salary,\n",
    "                salary_has_star=salary_has_star,\n",
    "                job_type_id=job_type_id,\n",
    "                location_id=location_id,\n",
    "                experience_level_id=experience_level_id\n",
    "            )\n",
    "            session.add(new_job)\n",
    "\n",
    "        # Commit the transaction\n",
    "        session.commit()\n",
    "        print('All rows inserted successfully')\n",
    "    except Exception as e:\n",
    "        # Roll back the transaction\n",
    "        session.rollback()\n",
    "        print('Error ',e)\n",
    "        print('No row inserted')\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the insertion went good\n",
    "jobs_df.shape[0] == session.query(Jobs).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job facilities df\n",
    "job_facilities_columns = job_columns + ['Facilities']\n",
    "job_facilities_df = df[job_facilities_columns].explode('Facilities', ignore_index=True)\n",
    "job_facilities_df['Facilities'] = job_facilities_df['Facilities'].apply(lambda x: str.lower(str.strip(x)))\n",
    "job_facilities_df.drop_duplicates(inplace=True)\n",
    "job_facilities_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8410 rows to insert\n",
      "\n",
      "Row 0 has a problem\n",
      "(pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of UNIQUE KEY constraint 'job_facility_UQ'. Cannot insert duplicate key in object 'dbo.job_facilities'. The duplicate key value is (1, 1). (2627) (SQLExecDirectW)\")\n",
      "[SQL: INSERT INTO job_facilities (job_id, facility_id) OUTPUT inserted.id VALUES (?, ?)]\n",
      "[parameters: (1, 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    }
   ],
   "source": [
    "# Insert into job facilities \n",
    "\n",
    "print(f\"{job_facilities_df.shape[0]} rows to insert\\n\")\n",
    "\n",
    "# Create a session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "for i in range(len(job_facilities_df)):\n",
    "    with session.begin():\n",
    "        try:\n",
    "            # Get job id\n",
    "            title = job_facilities_df['Job Title'][i]\n",
    "            salary = job_facilities_df['Salary'][i]\n",
    "            salary_has_star = job_facilities_df['Salary_has_star'][i]\n",
    "            job_type = job_facilities_df['Job Type'][i]\n",
    "            job_type_id = session.query(JobTypes).filter_by(type=job_type).first().id\n",
    "            location = job_facilities_df['Location'][i]\n",
    "            location_id = session.query(Locations).filter_by(location=location).first().id\n",
    "            experience_level = job_facilities_df['Experience level'][i]\n",
    "            experience_level_id = session.query(ExperienceLevels).filter_by(level=experience_level).first().id\n",
    "            job_id = session.query(Jobs).filter_by(\n",
    "                title=title,\n",
    "                salary=salary,\n",
    "                salary_has_star=salary_has_star,\n",
    "                job_type_id=job_type_id,\n",
    "                location_id=location_id,\n",
    "                experience_level_id=experience_level_id\n",
    "            ).first().id\n",
    "\n",
    "            # Get facility id\n",
    "            facility = job_facilities_df['Facilities'][i]\n",
    "            facility_id = session.query(Facilities).filter_by(facility=facility).first().id\n",
    "\n",
    "            # New row \n",
    "            new_row_job_facility = JobFacilities(job_id=job_id, facility_id=facility_id)\n",
    "            session.add(new_row_job_facility)\n",
    "\n",
    "            # Commit the transaction\n",
    "            session.commit()\n",
    "            print(f\"Row {i} inserted successfully\", end='\\r')\n",
    "        except Exception as e:\n",
    "            # Roll back the transaction\n",
    "            session.rollback()\n",
    "            print(f\"Row {i} has a problem\")\n",
    "            print(e)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the insertion went good\n",
    "job_facilities_df.shape[0] == session.query(JobFacilities).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job categories df\n",
    "job_categories_columns = job_columns + ['Job Category']\n",
    "job_categories_df = df[job_categories_columns].explode('Job Category', ignore_index=True)\n",
    "job_categories_df['Job Category'] = job_categories_df['Job Category'].apply(lambda x: str.lower(str.strip(x)))\n",
    "job_categories_df.drop_duplicates(inplace=True)\n",
    "job_categories_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3307 rows to insert\n",
      "\n",
      "Row 129 has a problemessfully\n",
      "(pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Violation of UNIQUE KEY constraint 'job_categories_UQ'. Cannot insert duplicate key in object 'dbo.job_categories'. The duplicate key value is (1, 110). (2627) (SQLExecDirectW)\")\n",
      "[SQL: INSERT INTO job_categories (category_id, job_id) OUTPUT inserted.id VALUES (?, ?)]\n",
      "[parameters: (1, 110)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    }
   ],
   "source": [
    "# Insert into job Categories\n",
    "print(f\"{job_categories_df.shape[0]} rows to insert\\n\")\n",
    "\n",
    "# Create a session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "for i in range(len(job_categories_df)):\n",
    "    with session.begin():\n",
    "        try:\n",
    "            # Get category id \n",
    "            category = job_categories_df['Job Category'][i]\n",
    "            category_id = session.query(Categories).filter_by(category=category).first().id\n",
    "\n",
    "            # Get job id\n",
    "            title = job_categories_df['Job Title'][i]\n",
    "            salary = job_categories_df['Salary'][i]\n",
    "            salary_has_star = job_categories_df['Salary_has_star'][i]\n",
    "            job_type = job_categories_df['Job Type'][i]\n",
    "            job_type_id = session.query(JobTypes).filter_by(type=job_type).first().id\n",
    "            location = job_categories_df['Location'][i]\n",
    "            location_id = session.query(Locations).filter_by(location=location).first().id\n",
    "            experience_level = job_categories_df['Experience level'][i]\n",
    "            experience_level_id = session.query(ExperienceLevels).filter_by(level=experience_level).first().id\n",
    "            job_id = session.query(Jobs).filter_by(\n",
    "                title=title,\n",
    "                salary=salary,\n",
    "                salary_has_star=salary_has_star,\n",
    "                job_type_id=job_type_id,\n",
    "                location_id=location_id,\n",
    "                experience_level_id=experience_level_id\n",
    "            ).first().id\n",
    "\n",
    "            # New row \n",
    "            new_row_job_category = JobCategories(job_id=job_id, category_id=category_id)\n",
    "            session.add(new_row_job_category)\n",
    "\n",
    "            # Commit the transaction\n",
    "            session.commit()\n",
    "            print(f\"Row {i} inserted successfully\", end='\\r')\n",
    "        except Exception as e:\n",
    "            # Roll back the transaction\n",
    "            session.rollback()\n",
    "            print(f\"Row {i} has a problem\")\n",
    "            print(e)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the insertion went good\n",
    "job_categories_df.shape[0] == session.query(JobCategories).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job requirements df\n",
    "job_requirements_columns = job_columns + ['Requirment of the company']\n",
    "job_requirements_df = df[job_requirements_columns].explode('Requirment of the company', ignore_index=True)\n",
    "job_requirements_df['Requirment of the company'] = job_requirements_df['Requirment of the company'].apply(lambda x: str.lower(str.strip(x)))\n",
    "job_requirements_df.drop_duplicates(inplace=True)\n",
    "job_requirements_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15980 rows to insert\n",
      "\n",
      "Row 15979 inserted successfully\r"
     ]
    }
   ],
   "source": [
    "# Insert into job requirements\n",
    "print(f\"{job_requirements_df.shape[0]} rows to insert\\n\")\n",
    "\n",
    "# Create a session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "for i in range(len(job_requirements_df)):\n",
    "    with session.begin():\n",
    "        try:\n",
    "            # Get requirement id \n",
    "            requirement = job_requirements_df['Requirment of the company'][i]\n",
    "            requirement_id = session.query(Requirements).filter_by(requirement=requirement).first().id\n",
    "\n",
    "            # Get job id\n",
    "            title = job_requirements_df['Job Title'][i]\n",
    "            salary = job_requirements_df['Salary'][i]\n",
    "            salary_has_star = job_requirements_df['Salary_has_star'][i]\n",
    "            job_type = job_requirements_df['Job Type'][i]\n",
    "            job_type_id = session.query(JobTypes).filter_by(type=job_type).first().id\n",
    "            location = job_requirements_df['Location'][i]\n",
    "            location_id = session.query(Locations).filter_by(location=location).first().id\n",
    "            experience_level = job_requirements_df['Experience level'][i]\n",
    "            experience_level_id = session.query(ExperienceLevels).filter_by(level=experience_level).first().id\n",
    "            job_id = session.query(Jobs).filter_by(\n",
    "                title=title,\n",
    "                salary=salary,\n",
    "                salary_has_star=salary_has_star,\n",
    "                job_type_id=job_type_id,\n",
    "                location_id=location_id,\n",
    "                experience_level_id=experience_level_id\n",
    "            ).first().id\n",
    "\n",
    "            # New row \n",
    "            new_row_job_requirement = JobRequirements(job_id=job_id, requirement_id=requirement_id)\n",
    "            session.add(new_row_job_requirement)\n",
    "\n",
    "            # Commit the transaction\n",
    "            session.commit()\n",
    "            print(f\"Row {i} inserted successfully\", end='\\r')\n",
    "        except Exception as e:\n",
    "            # Roll back the transaction\n",
    "            session.rollback()\n",
    "            print(f\"Row {i} has a problem\")\n",
    "            print(e)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the insertion went good\n",
    "job_requirements_df.shape[0] == session.query(JobRequirements).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse et visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quel est le marché le plus demandé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data Science': 1933,\n",
       " 'Big Data': 684,\n",
       " 'Artificial Intelligence': 632,\n",
       " 'Other': 58}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = session.query(Categories.category, func.count(JobCategories.job_id)).\\\n",
    "    join(Categories).\\\n",
    "    group_by(Categories.category).\\\n",
    "    order_by(desc(func.count(JobCategories.job_id))).\\\n",
    "    all()\n",
    "\n",
    "most_demanded_job = {x[0]: x[1] for x in result}\n",
    "\n",
    "most_demanded_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"c5197033-e335-48b7-bd89-f219c240eb9b\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"c5197033-e335-48b7-bd89-f219c240eb9b\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c5197033-e335-48b7-bd89-f219c240eb9b\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"e7c38637-d9d9-42aa-9c3e-92817dc794ea\" data-root-id=\"p1001\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"6a357f77-0fa5-4747-94d0-0fefae1de5e8\":{\"version\":\"3.2.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1001\",\"attributes\":{\"width\":400,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p1010\",\"attributes\":{\"factors\":[\"Data Science\",\"Big Data\",\"Artificial Intelligence\",\"Other\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1003\"},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p1011\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1012\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1008\",\"attributes\":{\"text\":\"Le march\\u00e9 les plus demand\\u00e9s\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1036\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1030\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1031\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1032\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[\"Data Science\",\"Big Data\",\"Artificial Intelligence\",\"Other\"]],[\"top\",[1933,684,632,58]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1037\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1038\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1033\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.5},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"fill_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"hatch_color\":{\"type\":\"value\",\"value\":\"darkblue\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1034\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.5},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p1035\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"width\":{\"type\":\"value\",\"value\":0.5},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"darkblue\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1009\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1023\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1024\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1025\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1026\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1027\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1028\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1029\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1018\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1019\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1020\"},\"axis_label\":\"Nombre d'apparition\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1021\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p1013\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p1014\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p1015\"},\"axis_label\":\"Job Categories\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1016\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1017\",\"attributes\":{\"axis\":{\"id\":\"p1013\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1022\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1018\"}}}]}}]}};\n  const render_items = [{\"docid\":\"6a357f77-0fa5-4747-94d0-0fefae1de5e8\",\"roots\":{\"p1001\":\"e7c38637-d9d9-42aa-9c3e-92817dc794ea\"},\"root_ids\":[\"p1001\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1001"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "jobs_categories = list(most_demanded_job.keys())\n",
    "job_counts = list(most_demanded_job.values())\n",
    "\n",
    "most_demanded_job_plot = figure(width=400, height=400, x_range=jobs_categories)\n",
    "most_demanded_job_plot.vbar(x=jobs_categories, top=job_counts, width=0.5, bottom=0, color='darkblue')\n",
    "\n",
    "# Labels\n",
    "most_demanded_job_plot.xaxis.axis_label = 'Job Categories'\n",
    "most_demanded_job_plot.yaxis.axis_label = 'Nombre d\\'apparition'\n",
    "most_demanded_job_plot.title.text = 'Le marché les plus demandés'\n",
    "\n",
    "show(most_demanded_job_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compétences les plus demandés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Job Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analysis</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWS</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Architecture</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Intelligence</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Agile</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excel</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data visualization</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Azure</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Python</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Consulting</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data quality</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Finance</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data management</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>APIs</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skill  Job Count\n",
       "0        Computer Science        687\n",
       "1             Engineering        668\n",
       "2           Data analysis        425\n",
       "3                     AWS        402\n",
       "4        Machine Learning        359\n",
       "5            Architecture        341\n",
       "6   Business Intelligence        336\n",
       "7                Big Data        329\n",
       "8                   Agile        317\n",
       "9          Data Analytics        294\n",
       "10                  Excel        272\n",
       "11     Data visualization        238\n",
       "12                  Azure        229\n",
       "13                 Python        208\n",
       "14          Deep Learning        204\n",
       "15             Consulting        193\n",
       "16           Data quality        174\n",
       "17                Finance        172\n",
       "18        Data management        172\n",
       "19                   APIs        171"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = session.query(Requirements.requirement, func.count(JobRequirements.job_id)).\\\n",
    "    join(JobRequirements).\\\n",
    "    join(Jobs).\\\n",
    "    join(JobCategories).\\\n",
    "    join(Categories).\\\n",
    "    filter(Categories.category=='data science').\\\n",
    "    group_by(Requirements.requirement).\\\n",
    "    order_by(desc(func.count(JobCategories.job_id))).\\\n",
    "    all()\n",
    "\n",
    "most_demand_skills = {x[0]: x[1] for x in result}\n",
    "most_demand_skills_df = pd.DataFrame(data=list(most_demand_skills.items()), columns=['Skill', 'Job Count'])\n",
    "most_demand_skills_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_demand_skills_df = pd.DataFrame(most_demand_skills, columns=['Skills', 'Repetition_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to het the most demanded skills\n",
    "def get_requirements_count_by_category(category_name):\n",
    "    query = text(f\"SELECT * FROM GetRequirementsCountByCategory(:categoryName) ORDER BY job_count DESC\")\n",
    "    result = session.execute(query, {'categoryName': category_name})\n",
    "    # Create dict containing results\n",
    "    most_demand_skills = {x[0]: x[1] for x in result.fetchall()}\n",
    "    # Transform dict to dataframe\n",
    "    most_demand_skills_df = pd.DataFrame(data=list(most_demand_skills.items()), columns=['Skill', 'Job Count'])\n",
    "    return most_demand_skills_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Science "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(pyodbc.ProgrammingError) ('42S02', \"[42S02] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid object name 'GetRequirementsCountByCategory'. (208) (SQLExecDirectW)\")\n[SQL: SELECT * FROM GetRequirementsCountByCategory(?) ORDER BY job_count DESC]\n[parameters: ('data science',)]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: ('42S02', \"[42S02] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid object name 'GetRequirementsCountByCategory'. (208) (SQLExecDirectW)\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve requirements from database and their counts where category is Data Science\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_science_skills \u001b[38;5;241m=\u001b[39m \u001b[43mget_requirements_count_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata science\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m data_science_skills\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[49], line 4\u001b[0m, in \u001b[0;36mget_requirements_count_by_category\u001b[0;34m(category_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_requirements_count_by_category\u001b[39m(category_name):\n\u001b[1;32m      3\u001b[0m     query \u001b[38;5;241m=\u001b[39m text(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM GetRequirementsCountByCategory(:categoryName) ORDER BY job_count DESC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategoryName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory_name\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Create dict containing results\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     most_demand_skills \u001b[38;5;241m=\u001b[39m {x[\u001b[38;5;241m0\u001b[39m]: x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mfetchall()}\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2246\u001b[0m, in \u001b[0;36mSession.execute\u001b[0;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\n\u001b[1;32m   2186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2187\u001b[0m     statement: Executable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     _add_event: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2194\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Result[Any]:\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Execute a SQL expression construct.\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m \n\u001b[1;32m   2197\u001b[0m \u001b[38;5;124;03m    Returns a :class:`_engine.Result` object representing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2244\u001b[0m \n\u001b[1;32m   2245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2251\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2252\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_add_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_add_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2150\u001b[0m, in \u001b[0;36mSession._execute_internal\u001b[0;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     result: Result[Any] \u001b[38;5;241m=\u001b[39m compile_state_cls\u001b[38;5;241m.\u001b[39morm_execute_statement(\n\u001b[1;32m   2142\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2143\u001b[0m         statement,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         conn,\n\u001b[1;32m   2148\u001b[0m     )\n\u001b[1;32m   2149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2150\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m   2152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _scalar_result:\n\u001b[1;32m   2155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mscalar()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1412\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:483\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1635\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1623\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1625\u001b[0m )\n\u001b[1;32m   1627\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1628\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1629\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1634\u001b[0m )\n\u001b[0;32m-> 1635\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1648\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1649\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1650\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         ret,\n\u001b[1;32m   1655\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1840\u001b[0m         dialect,\n\u001b[1;32m   1841\u001b[0m         context,\n\u001b[1;32m   1842\u001b[0m     )\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1984\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2339\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1972\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1977\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (pyodbc.ProgrammingError) ('42S02', \"[42S02] [Microsoft][ODBC Driver 18 for SQL Server][SQL Server]Invalid object name 'GetRequirementsCountByCategory'. (208) (SQLExecDirectW)\")\n[SQL: SELECT * FROM GetRequirementsCountByCategory(?) ORDER BY job_count DESC]\n[parameters: ('data science',)]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "# Retrieve requirements from database and their counts where category is Data Science\n",
    "data_science_skills = get_requirements_count_by_category('data science')\n",
    "data_science_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly express\n",
    "import plotly.express as px\n",
    "\n",
    "number_of_line = 20\n",
    "skills = data_science_skills.head(number_of_line)['Skill']\n",
    "jobs_counts = data_science_skills.head(number_of_line)['Job Count']\n",
    "\n",
    "# Create the bar chart\n",
    "skills_fig = px.bar(\n",
    "    x=skills, \n",
    "    y=jobs_counts, \n",
    "    labels={'x': 'Compétences', 'y': 'Nombre de demandes'}, title='Compétences les plus demandés en Data Science',\n",
    "    color=data_science_skills.head(number_of_line)['Job Count']\n",
    ")\n",
    "\n",
    "\n",
    "# Customize the layout\n",
    "skills_fig.update_layout(\n",
    "    title_font=dict(size=24),\n",
    "    xaxis=dict(title_font=dict(size=16)),\n",
    "    yaxis=dict(title_font=dict(size=16)),\n",
    "    font=dict(size=14),\n",
    "    font_color='white',\n",
    "    plot_bgcolor='#101F6A',\n",
    "    paper_bgcolor='#17266D',\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=True\n",
    ")\n",
    "\n",
    "# Show the plot in notebook\n",
    "skills_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve requirements where category is Big DATA\n",
    "big_data_skills = get_requirements_count_by_category('Big data')\n",
    "big_data_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly express\n",
    "import plotly.express as px\n",
    "\n",
    "number_of_line = 20\n",
    "skills = big_data_skills.head(number_of_line)['Skill']\n",
    "jobs_counts = big_data_skills.head(number_of_line)['Job Count']\n",
    "\n",
    "# Create the bar chart\n",
    "skills_fig = px.bar(\n",
    "    x=skills, \n",
    "    y=jobs_counts, \n",
    "    labels={'x': 'Compétences', 'y': 'Nombre de demandes'}, title='Compétences les plus demandés en Big DATA',\n",
    ")\n",
    "\n",
    "\n",
    "# Customize the layout\n",
    "skills_fig.update_layout(\n",
    "    title_font=dict(size=24),\n",
    "    xaxis=dict(title_font=dict(size=16)),\n",
    "    yaxis=dict(title_font=dict(size=16)),\n",
    "    font=dict(size=14),\n",
    "    font_color='white',\n",
    "    plot_bgcolor='#101F6A',\n",
    "    paper_bgcolor='#17266D',\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False\n",
    ")\n",
    "\n",
    "# Show the plot in notebook\n",
    "skills_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_skills = get_requirements_count_by_category('artificial intelligence')\n",
    "ai_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly express\n",
    "import plotly.express as px\n",
    "\n",
    "number_of_line = 20\n",
    "skills = ai_skills.head(number_of_line)['Skill']\n",
    "jobs_counts = ai_skills.head(number_of_line)['Job Count']\n",
    "\n",
    "# Create the bar chart\n",
    "skills_fig = px.bar(\n",
    "    x=skills, \n",
    "    y=jobs_counts, \n",
    "    labels={'x': 'Compétences', 'y': 'Nombre de demandes'}, title='Compétences les plus demandés en Intelligence Artificielle',\n",
    "    color=jobs_counts,\n",
    "    color_continuous_scale='Blues'\n",
    ")\n",
    "\n",
    "\n",
    "# Customize the layout\n",
    "skills_fig.update_layout(\n",
    "    title_font=dict(size=24),\n",
    "    xaxis=dict(title_font=dict(size=16)),\n",
    "    yaxis=dict(title_font=dict(size=16)),\n",
    "    font=dict(size=14),\n",
    "    font_color='white',\n",
    "    plot_bgcolor='#101F6A',\n",
    "    paper_bgcolor='#17266D',\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False\n",
    ")\n",
    "\n",
    "# Show the plot in notebook\n",
    "skills_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarité et différences des compétences entre IA, Data Science et Big DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distinct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mquery(Requirements\u001b[38;5;241m.\u001b[39mrequirement)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      2\u001b[0m     join(JobRequirements)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      3\u001b[0m     join(Jobs)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      4\u001b[0m     join(JobCategories)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      5\u001b[0m     join(Categories)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mfilter\u001b[39m(Categories\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39min_([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata science\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124martificial intelligence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbig data\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      7\u001b[0m     group_by(Requirements\u001b[38;5;241m.\u001b[39mrequirement)\u001b[38;5;241m.\u001b[39m\\\n\u001b[0;32m----> 8\u001b[0m     having(func\u001b[38;5;241m.\u001b[39mcount(\u001b[43mdistinct\u001b[49m(Categories\u001b[38;5;241m.\u001b[39mid)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mall\u001b[39m()\n\u001b[1;32m     10\u001b[0m skills_similarity \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distinct' is not defined"
     ]
    }
   ],
   "source": [
    "result = session.query(Requirements.requirement).\\\n",
    "    join(JobRequirements).\\\n",
    "    join(Jobs).\\\n",
    "    join(JobCategories).\\\n",
    "    join(Categories).\\\n",
    "    filter(Categories.category.in_(['data science', 'artificial intelligence', 'big data'])).\\\n",
    "    group_by(Requirements.requirement).\\\n",
    "    having(func.count(distinct(Categories.id)) == 3).\\\n",
    "    all()\n",
    "skills_similarity = [x[0] for x in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Number of rows\n",
    "number_of_row = 10\n",
    "\n",
    "data_science = set(data_science_skills['Skill'].head(number_of_row))\n",
    "artificial_intelligence = set(ai_skills['Skill'].head(number_of_row))\n",
    "big_data = set(big_data_skills['Skill'].head(number_of_row))\n",
    "\n",
    "# Create the Venn diagram\n",
    "venn = venn3([data_science, artificial_intelligence, big_data], set_labels=('Data Science', 'Artificial Intelligence', 'Big Data'))\n",
    "\n",
    "# Add custom labels for each set\n",
    "venn.get_label_by_id('100').set_text('\\n'.join(artificial_intelligence - data_science - big_data))\n",
    "venn.get_label_by_id('010').set_text('\\n'.join(data_science - artificial_intelligence - big_data))\n",
    "venn.get_label_by_id('001').set_text('\\n'.join(big_data - artificial_intelligence - data_science))\n",
    "venn.get_label_by_id('110').set_text('\\n'.join(artificial_intelligence & data_science - big_data))\n",
    "venn.get_label_by_id('101').set_text('\\n'.join(artificial_intelligence & big_data - data_science))\n",
    "venn.get_label_by_id('011').set_text('\\n'.join(data_science & big_data - artificial_intelligence))\n",
    "venn.get_label_by_id('111').set_text('\\n'.join(artificial_intelligence & data_science & big_data))\n",
    "\n",
    "# Customize the Venn diagram\n",
    "venn_circles = venn3_circles([data_science, artificial_intelligence, big_data], linestyle='dashed', linewidth=1, color='grey')\n",
    "\n",
    "plt.title('Similarités et différences entre les domaines', fontsize=16)\n",
    "# Show the Venn diagram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les postes les plus courants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = session.query(Jobs.title, func.count(Jobs.title)).group_by(Jobs.title).order_by(desc(func.count(Jobs.title))).all()\n",
    "most_job_title = {x[0]: x[1] for x in result}\n",
    "most_job_title_df = pd.DataFrame(list(most_job_title.items()), columns=['Job Title', 'job_counts'])\n",
    "most_job_title_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create a WordCloud object with custom settings\n",
    "wordcloud = WordCloud(\n",
    "    background_color='white',\n",
    "    colormap='viridis',\n",
    "    contour_color='steelblue',\n",
    "    prefer_horizontal=1,  # Horizontal layout of words\n",
    "    relative_scaling=0.5,  # Adjusts the font size based on counts\n",
    ").generate_from_frequencies(most_job_title)\n",
    "\n",
    "# Display the WordCloud using matplotlib\n",
    "plt.figure(figsize=(10, 6))  # Set the size of the figure (width, height)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Top Job Titles by Count', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
